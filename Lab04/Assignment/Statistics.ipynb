{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b1b906-58e7-4e7a-a6ae-1c16f179931e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838be7c7-1774-4197-a1a9-78afcbfa7dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from time import time, sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41356d7f-c57e-4e69-9100-d9145ce2f9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610084f8-117f-4ac6-86d4-b9ec56d72e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_list, transform=None):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_dict = self.data_list[idx]\n",
    "        img_path_1 = data_dict['img1']\n",
    "        \n",
    "        img_1 = Image.open(img_path_1).convert(\"RGB\")\n",
    "        img_1 = self.transform(img_1)\n",
    "        \n",
    "        return img_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9610a1-d1f5-4f35-81bb-d6067091c105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dd226d-ae31-4b9e-9cc1-3472e99df94b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n"
     ]
    }
   ],
   "source": [
    "fold = []\n",
    "\n",
    "path = './Homework Dataset'\n",
    "for idx, it in enumerate(os.listdir(path)):\n",
    "    full_paths = []\n",
    "    semi_full = os.path.join(os.path.join(path, it), 'images')\n",
    "    for it2 in sorted(os.listdir(semi_full)):\n",
    "        full_path = os.path.join(semi_full, it2)\n",
    "        full_paths.append(full_path)\n",
    "    for x in range(len(full_paths)):\n",
    "        fold.append({\"img1\": full_paths[x]})\n",
    "            \n",
    "print(len(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04f6607-494e-4104-ac02-b2c792db36c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ImageDataset(fold, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bb9895-a720-4033-bc27-10c137cc299c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.4654), tensor(0.4655), tensor(0.4654)],\n",
       " [tensor(0.2362), tensor(0.2349), tensor(0.2349)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataset_statistics(dataset):\n",
    "    mean = [0, 0, 0]\n",
    "    std = [0, 0, 0]\n",
    "\n",
    "    std[0], mean[0] = torch.std_mean(torch.cat([dataset[i][0][0].flatten() for i in range(len(dataset))]))\n",
    "    std[1], mean[1] = torch.std_mean(torch.cat([dataset[i][0][1].flatten() for i in range(len(dataset))]))\n",
    "    std[2], mean[2] = torch.std_mean(torch.cat([dataset[i][0][2].flatten() for i in range(len(dataset))]))\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "mean, std = dataset_statistics(ds)\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157af1c3-bb74-4378-9e71-f9477ee62aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
